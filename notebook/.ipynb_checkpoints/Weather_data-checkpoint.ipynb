{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "### Hi Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cathe\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2714: DtypeWarning: Columns (29,34,35,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\cathe\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2714: DtypeWarning: Columns (28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n",
      "C:\\Users\\cathe\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2714: DtypeWarning: Columns (26,28) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir('C:\\Users\\cathe\\Documents\\Python docs\\UFO_sightings\\UFO-Sightings-Analysis\\data')\n",
    "\n",
    "df_2018 = pd.read_csv('Storm_event_details2018.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_2017 = pd.read_csv('Storm_event_details2017.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_2016 = pd.read_csv('Storm_event_details2016.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_2015 = pd.read_csv('Storm_event_details2015.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_2014 = pd.read_csv('Storm_event_details2014.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_2013 = pd.read_csv('Storm_event_details2013.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_2012 = pd.read_csv('Storm_event_details2012.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_2011 = pd.read_csv('Storm_event_details2011.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_2010 = pd.read_csv('Storm_event_details2010.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_2009 = pd.read_csv('Storm_event_details2009.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_2008 = pd.read_csv('Storm_event_details2008.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_2007 = pd.read_csv('Storm_event_details2007.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_2006 = pd.read_csv('Storm_event_details2006.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_2005 = pd.read_csv('Storm_event_details2005.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_2004 = pd.read_csv('Storm_event_details2004.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_2003 = pd.read_csv('Storm_event_details2003.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_2002 = pd.read_csv('Storm_event_details2002.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_2001 = pd.read_csv('Storm_event_details2001.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_2000 = pd.read_csv('Storm_event_details2000.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1999 = pd.read_csv('Storm_event_details1999.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1998 = pd.read_csv('Storm_event_details1998.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1997 = pd.read_csv('Storm_event_details1997.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1996 = pd.read_csv('Storm_event_details1996.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1995 = pd.read_csv('Storm_event_details1995.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1994 = pd.read_csv('Storm_event_details1994.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1993 = pd.read_csv('Storm_event_details1993.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1992 = pd.read_csv('Storm_event_details1992.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1991 = pd.read_csv('Storm_event_details1991.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1990 = pd.read_csv('Storm_event_details1990.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1989 = pd.read_csv('Storm_event_details1989.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1988 = pd.read_csv('Storm_event_details1988.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1987 = pd.read_csv('Storm_event_details1987.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1986 = pd.read_csv('Storm_event_details1986.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1985 = pd.read_csv('Storm_event_details1985.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1984 = pd.read_csv('Storm_event_details1984.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1983 = pd.read_csv('Storm_event_details1983.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1982 = pd.read_csv('Storm_event_details1982.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1981 = pd.read_csv('Storm_event_details1981.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1980 = pd.read_csv('Storm_event_details1980.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1979 = pd.read_csv('Storm_event_details1979.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1978 = pd.read_csv('Storm_event_details1978.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1977 = pd.read_csv('Storm_event_details1977.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1976 = pd.read_csv('Storm_event_details1976.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1975 = pd.read_csv('Storm_event_details1975.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1974 = pd.read_csv('Storm_event_details1974.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1973 = pd.read_csv('Storm_event_details1973.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1972 = pd.read_csv('Storm_event_details1972.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1971 = pd.read_csv('Storm_event_details1971.csv.gz', compression='gzip',error_bad_lines=False)\n",
    "df_1970 = pd.read_csv('Storm_event_details1970.csv.gz', compression='gzip',error_bad_lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "event_details = df_2018.append([df_2017,df_2016,df_2015,df_2014,df_2013])\n",
    "event_details = event_details.append([df_2012,df_2011,df_2010,df_2009,df_2008])      \n",
    "event_details = event_details.append([df_2007,df_2006,df_2005,df_2004,df_2003])\n",
    "event_details = event_details.append([df_2002,df_2001,df_2000,df_1999,df_1998])\n",
    "event_details = event_details.append([df_1997,df_1996,df_1995,df_1994,df_1993])\n",
    "event_details = event_details.append([df_1992,df_1991,df_1990,df_1989,df_1988])\n",
    "event_details = event_details.append([df_1987,df_1986,df_1985,df_1984,df_1983])\n",
    "event_details = event_details.append([df_1982,df_1981,df_1980,df_1979,df_1978])\n",
    "event_details = event_details.append([df_1977,df_1976,df_1975,df_1974,df_1973])\n",
    "event_details = event_details.append([df_1972,df_1971,df_1970])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather = event_details[['BEGIN_YEARMONTH','BEGIN_DAY','BEGIN_TIME','STATE','YEAR','MONTH_NAME','EVENT_TYPE']]\n",
    "weather = weather.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['YEAR'] = weather['BEGIN_YEARMONTH'].astype(str).str[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'January':1,'February':2,'March':3,'April':4,'May':5,'June':6,'July':7,'August':8,'September':9,'October':10,'November':11,'December':12}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather.MONTH_NAME = weather['MONTH_NAME'].map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "weather['Date'] = weather['YEAR'].astype(str) + '-' + weather['MONTH_NAME'].astype(str)+ '-' + weather['BEGIN_DAY'].astype(str)\n",
    "weather['Date'] = pd.to_datetime(weather['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>TEXAS</td>\n",
       "      <td>Drought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-15</th>\n",
       "      <td>OKLAHOMA</td>\n",
       "      <td>Wildfire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-06</th>\n",
       "      <td>WEST VIRGINIA</td>\n",
       "      <td>Winter Weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-19</th>\n",
       "      <td>NEW MEXICO</td>\n",
       "      <td>High Wind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-17</th>\n",
       "      <td>NEW JERSEY</td>\n",
       "      <td>Winter Weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>MISSOURI</td>\n",
       "      <td>Drought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-01</th>\n",
       "      <td>ILLINOIS</td>\n",
       "      <td>Drought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-21</th>\n",
       "      <td>LOUISIANA</td>\n",
       "      <td>Flash Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-01-22</th>\n",
       "      <td>MISSOURI</td>\n",
       "      <td>Thunderstorm Wind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-07</th>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>Winter Storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-12</th>\n",
       "      <td>COLORADO</td>\n",
       "      <td>Winter Storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-12</th>\n",
       "      <td>COLORADO</td>\n",
       "      <td>Winter Weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-07</th>\n",
       "      <td>MISSISSIPPI</td>\n",
       "      <td>Tornado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-17</th>\n",
       "      <td>WYOMING</td>\n",
       "      <td>Winter Storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-03</th>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>Coastal Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-01</th>\n",
       "      <td>KANSAS</td>\n",
       "      <td>Drought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-06</th>\n",
       "      <td>KANSAS</td>\n",
       "      <td>High Wind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-24</th>\n",
       "      <td>ILLINOIS</td>\n",
       "      <td>Heavy Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-17</th>\n",
       "      <td>MONTANA</td>\n",
       "      <td>Winter Storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-17</th>\n",
       "      <td>MONTANA</td>\n",
       "      <td>Heavy Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-24</th>\n",
       "      <td>IDAHO</td>\n",
       "      <td>Heavy Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-12</th>\n",
       "      <td>CONNECTICUT</td>\n",
       "      <td>Winter Weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-12</th>\n",
       "      <td>CONNECTICUT</td>\n",
       "      <td>Heavy Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-20</th>\n",
       "      <td>WISCONSIN</td>\n",
       "      <td>Flood</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-02</th>\n",
       "      <td>NEW YORK</td>\n",
       "      <td>High Wind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-14</th>\n",
       "      <td>NEVADA</td>\n",
       "      <td>Heavy Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-02</th>\n",
       "      <td>NEVADA</td>\n",
       "      <td>Winter Storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-04</th>\n",
       "      <td>NEVADA</td>\n",
       "      <td>Avalanche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>WISCONSIN</td>\n",
       "      <td>Winter Weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-03-23</th>\n",
       "      <td>IOWA</td>\n",
       "      <td>Heavy Snow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-08-16</th>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>Marine High Wind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-09-25</th>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>Tropical Storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997-09-25</th>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>Tropical Storm</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-01-05</th>\n",
       "      <td>NEW HAMPSHIRE</td>\n",
       "      <td>Avalanche</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-04-16</th>\n",
       "      <td>MAINE</td>\n",
       "      <td>Debris Flow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-06-17</th>\n",
       "      <td>MINNESOTA</td>\n",
       "      <td>Debris Flow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-06-03</th>\n",
       "      <td>ARIZONA</td>\n",
       "      <td>Waterspout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-05-26</th>\n",
       "      <td>NEW HAMPSHIRE</td>\n",
       "      <td>Dust Devil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-12-17</th>\n",
       "      <td>LOUISIANA</td>\n",
       "      <td>Freezing Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-02-22</th>\n",
       "      <td>VERMONT</td>\n",
       "      <td>Dense Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-09-02</th>\n",
       "      <td>MAINE</td>\n",
       "      <td>Hurricane (Typhoon)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-07-13</th>\n",
       "      <td>RHODE ISLAND</td>\n",
       "      <td>Waterspout</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-12-02</th>\n",
       "      <td>CALIFORNIA</td>\n",
       "      <td>Marine High Wind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-11-01</th>\n",
       "      <td>NORTH DAKOTA</td>\n",
       "      <td>Freezing Fog</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996-09-02</th>\n",
       "      <td>NEW HAMPSHIRE</td>\n",
       "      <td>Hurricane (Typhoon)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-06-01</th>\n",
       "      <td>NEVADA</td>\n",
       "      <td>HAIL FLOODING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-08-05</th>\n",
       "      <td>NEVADA</td>\n",
       "      <td>THUNDERSTORM WINDS/FLASH FLOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-08-19</th>\n",
       "      <td>TENNESSEE</td>\n",
       "      <td>THUNDERSTORM WINDS LIGHTNING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-06-12</th>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>THUNDERSTORM WIND/ TREES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-06-12</th>\n",
       "      <td>NORTH CAROLINA</td>\n",
       "      <td>THUNDERSTORM WIND/ TREE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-07-17</th>\n",
       "      <td>PENNSYLVANIA</td>\n",
       "      <td>THUNDERSTORM WINDS FUNNEL CLOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-09-02</th>\n",
       "      <td>NEVADA</td>\n",
       "      <td>THUNDERSTORM WINDS FUNNEL CLOU</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-07-16</th>\n",
       "      <td>NEW JERSEY</td>\n",
       "      <td>TORNADO/WATERSPOUT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-06-22</th>\n",
       "      <td>MINNESOTA</td>\n",
       "      <td>THUNDERSTORM WINDS/HEAVY RAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-09-01</th>\n",
       "      <td>VIRGINIA</td>\n",
       "      <td>THUNDERSTORM WINDS HEAVY RAIN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-04-04</th>\n",
       "      <td>TEXAS</td>\n",
       "      <td>THUNDERSTORM WINDS/ FLOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995-06-01</th>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>THUNDERSTORM WINDS LIGHTNING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-04-15</th>\n",
       "      <td>SOUTH CAROLINA</td>\n",
       "      <td>THUNDERSTORM WINDS/FLOODING</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1994-06-09</th>\n",
       "      <td>OREGON</td>\n",
       "      <td>HAIL/ICY ROADS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1993-03-12</th>\n",
       "      <td>FLORIDA</td>\n",
       "      <td>TORNADOES, TSTM WIND, HAIL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1742 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     STATE                      EVENT_TYPE\n",
       "Date                                                      \n",
       "2018-02-01           TEXAS                         Drought\n",
       "2018-02-15        OKLAHOMA                        Wildfire\n",
       "2018-02-06   WEST VIRGINIA                  Winter Weather\n",
       "2018-02-19      NEW MEXICO                       High Wind\n",
       "2018-02-17      NEW JERSEY                  Winter Weather\n",
       "2018-01-01        MISSOURI                         Drought\n",
       "2018-01-01        ILLINOIS                         Drought\n",
       "2018-02-21       LOUISIANA                     Flash Flood\n",
       "2018-01-22        MISSOURI               Thunderstorm Wind\n",
       "2018-02-07        NEW YORK                    Winter Storm\n",
       "2018-02-12        COLORADO                    Winter Storm\n",
       "2018-02-12        COLORADO                  Winter Weather\n",
       "2018-02-07     MISSISSIPPI                         Tornado\n",
       "2018-02-17         WYOMING                    Winter Storm\n",
       "2018-03-03        NEW YORK                   Coastal Flood\n",
       "2018-03-01          KANSAS                         Drought\n",
       "2018-03-06          KANSAS                       High Wind\n",
       "2018-03-24        ILLINOIS                      Heavy Snow\n",
       "2018-02-17         MONTANA                    Winter Storm\n",
       "2018-02-17         MONTANA                      Heavy Snow\n",
       "2018-02-24           IDAHO                      Heavy Snow\n",
       "2018-03-12     CONNECTICUT                  Winter Weather\n",
       "2018-03-12     CONNECTICUT                      Heavy Snow\n",
       "2018-02-20       WISCONSIN                           Flood\n",
       "2018-03-02        NEW YORK                       High Wind\n",
       "2018-03-14          NEVADA                      Heavy Snow\n",
       "2018-03-02          NEVADA                    Winter Storm\n",
       "2018-03-04          NEVADA                       Avalanche\n",
       "2018-02-05       WISCONSIN                  Winter Weather\n",
       "2018-03-23            IOWA                      Heavy Snow\n",
       "...                    ...                             ...\n",
       "1997-08-16    PENNSYLVANIA                Marine High Wind\n",
       "1997-09-25      CALIFORNIA                  Tropical Storm\n",
       "1997-09-25         ARIZONA                  Tropical Storm\n",
       "1996-01-05   NEW HAMPSHIRE                       Avalanche\n",
       "1996-04-16           MAINE                     Debris Flow\n",
       "1996-06-17       MINNESOTA                     Debris Flow\n",
       "1996-06-03         ARIZONA                      Waterspout\n",
       "1996-05-26   NEW HAMPSHIRE                      Dust Devil\n",
       "1996-12-17       LOUISIANA                    Freezing Fog\n",
       "1996-02-22         VERMONT                       Dense Fog\n",
       "1996-09-02           MAINE             Hurricane (Typhoon)\n",
       "1996-07-13    RHODE ISLAND                      Waterspout\n",
       "1996-12-02      CALIFORNIA                Marine High Wind\n",
       "1996-11-01    NORTH DAKOTA                    Freezing Fog\n",
       "1996-09-02   NEW HAMPSHIRE             Hurricane (Typhoon)\n",
       "1995-06-01          NEVADA                   HAIL FLOODING\n",
       "1995-08-05          NEVADA  THUNDERSTORM WINDS/FLASH FLOOD\n",
       "1995-08-19       TENNESSEE    THUNDERSTORM WINDS LIGHTNING\n",
       "1995-06-12  NORTH CAROLINA        THUNDERSTORM WIND/ TREES\n",
       "1995-06-12  NORTH CAROLINA         THUNDERSTORM WIND/ TREE\n",
       "1995-07-17    PENNSYLVANIA  THUNDERSTORM WINDS FUNNEL CLOU\n",
       "1995-09-02          NEVADA  THUNDERSTORM WINDS FUNNEL CLOU\n",
       "1995-07-16      NEW JERSEY              TORNADO/WATERSPOUT\n",
       "1995-06-22       MINNESOTA   THUNDERSTORM WINDS/HEAVY RAIN\n",
       "1995-09-01        VIRGINIA   THUNDERSTORM WINDS HEAVY RAIN\n",
       "1995-04-04           TEXAS       THUNDERSTORM WINDS/ FLOOD\n",
       "1995-06-01  SOUTH CAROLINA    THUNDERSTORM WINDS LIGHTNING\n",
       "1994-04-15  SOUTH CAROLINA     THUNDERSTORM WINDS/FLOODING\n",
       "1994-06-09          OREGON                  HAIL/ICY ROADS\n",
       "1993-03-12         FLORIDA      TORNADOES, TSTM WIND, HAIL\n",
       "\n",
       "[1742 rows x 2 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weathermap = weather[['Date','STATE','EVENT_TYPE']]\n",
    "weathermap.set_index('Date',inplace=True)\n",
    "\n",
    "weathermap.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = {\n",
    "    'ALABAMA': 'AL',\n",
    "    'ALASKA': 'AK',\n",
    "    'ARIZONA': 'AZ',\n",
    "    'ARKANSAS': 'AR',\n",
    "    'CALIFORNIA': 'CA',\n",
    "    'COLORADO': 'CO',\n",
    "    'CONNECTICUT': 'CT',\n",
    "    'DELAWARE': 'DE',\n",
    "    'FLORIDA': 'FL',\n",
    "    'GEORGIA': 'GA',\n",
    "    'HAWAII': 'HI',\n",
    "    'IDAHO': 'ID',\n",
    "    'ILLINOIS': 'IL',\n",
    "    'INDIANA': 'IN',\n",
    "    'IOWA': 'IA',\n",
    "    'KANSAS': 'KS',\n",
    "    'KENTUCKY': 'KY',\n",
    "    'LOUISIANA': 'LA',\n",
    "    'MAINE': 'ME',\n",
    "    'MARYLAND': 'MD',\n",
    "    'MASSACHUSETTS': 'MA',\n",
    "    'MICHIGAN': 'MI',\n",
    "    'MINNESOTA': 'MN',\n",
    "    'MISSIPPI': 'MS',\n",
    "    'MISSOURI': 'MO',\n",
    "    'MONTANA': 'MT',\n",
    "    'NEBRASKA': 'NE',\n",
    "    'NEVADA': 'NV',\n",
    "    'NEW HAMPSHIRE': 'NH',\n",
    "    'NEW JERSEY': 'NJ',\n",
    "    'NEW MEXICO': 'NM',\n",
    "    'NEW YORK': 'NY',\n",
    "    'NORTH CAROLINA': 'NC',\n",
    "    'NORTH DAKOTA': 'ND',\n",
    "    'OHIO': 'OH',\n",
    "    'OKLAHOMA': 'OK',\n",
    "    'OREGON': 'OR',\n",
    "    'PENNSYLVANIA': 'PA',\n",
    "    'RHODE ISLAND': 'RI',\n",
    "    'SOUTH CAROLINA': 'SC',\n",
    "    'SOUTH DAKOTA': 'SD',\n",
    "    'TENNESSEE': 'TN',\n",
    "    'TEXAS': 'TX',\n",
    "    'UTAH': 'UT',\n",
    "    'VERMONT': 'VT',\n",
    "    'VIRGINIA': 'VA',\n",
    "    'WASHINGTON': 'WA',\n",
    "    'WEST VIRGINA': 'WV',\n",
    "    'WISCONSIN': 'WI',\n",
    "    'WYOMING': 'WY',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cathe\\Anaconda2\\lib\\site-packages\\pandas\\core\\generic.py:4401: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self[name] = value\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>STATE</th>\n",
       "      <th>EVENT_TYPE</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-01</th>\n",
       "      <td>TX</td>\n",
       "      <td>Drought</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-15</th>\n",
       "      <td>OK</td>\n",
       "      <td>Wildfire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-18</th>\n",
       "      <td>OK</td>\n",
       "      <td>Wildfire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-06</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Winter Weather</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-19</th>\n",
       "      <td>NM</td>\n",
       "      <td>High Wind</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           STATE      EVENT_TYPE\n",
       "Date                            \n",
       "2018-02-01    TX         Drought\n",
       "2018-02-15    OK        Wildfire\n",
       "2018-02-18    OK        Wildfire\n",
       "2018-02-06   NaN  Winter Weather\n",
       "2018-02-19    NM       High Wind"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weathermap.STATE = weathermap['STATE'].map(states)\n",
    "weathermap[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "weathermap = weathermap.dropna()\n",
    "weathermap = weathermap[weathermap.EVENT_TYPE != 'Drought']\n",
    "weathermap = weathermap[weathermap.EVENT_TYPE != 'Flood']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "weathermap.to_csv('weather.csv',sep=',', encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
